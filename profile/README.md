# AIR-DREAM Lab
:raised_hands: Welcome to AIR-DREAM (Decision-making Research for Empowered AI Methods) Lab code repository! AIR-DREAM is a research group at [Institute for AI Industry Research (AIR)](https://air.tsinghua.edu.cn/en/), Tsinghua University. Our research focus is to develop advanced learning-based data-driven decision-making theories and practical technologies that are robust, generalizable, and deployable to tackle real-world challenges. We work on fundamental learning algorithms, embodied AI, optimization technologies for real-world AIoT systems, and data-driven decision-making tools & libraries.

Current available offline RL/IL algorithms, embodied AI models, and tools/libraries in our code repository include:

Algorithms:

- [Flow-Planner (NeurIPS 2025): Flow Matching-Based Autonomous Driving Planning with Advanced Interactive Behavior Modeling](https://github.com/THU-AIR-DREAM/Flow-Planner)
- [X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model](https://github.com/THU-AIR-DREAM/X-VLA.)
- [LBP (ICML 2025): Efficient Robotic Policy Learning via Latent Space Backward Planning](https://github.com/AIR-DI/LBP)
- [UniAct (CVPR 2025): Universal Actions for Enhanced Embodied Foundation Models](https://github.com/AIR-DI/UniAct)
- [Robo-MUTUAL (ICRA 2025): Robotic Multimodal Task specifications via Unimodal Learning](https://github.com/AIR-DI/Robo_MUTUAL)
- [H2O+ (ICRA 2025): An Improved Framework for Hybrid Offline-and-Online RL with Dynamics Gaps](https://github.com/AIR-DI/H2Oplus)
- [Diffusion-Planner (ICLR 2025 oral): Diffusion-Based Planning for Autonomous Driving with Flexible Guidance](https://github.com/AIR-DI/Diffusion-Planner)
- [PSEC (ICLR 2025): Skill Expansion and Composition in Parameter Space](https://github.com/AIR-DI/PSEC)
- [RSP (AAAI 2025 oral): Recursive Skip-Step Planning](https://github.com/AIR-DI/RSP_JAX)
- [IVM (NeurIPS 2025): Instruction-Guided Visual Masking](https://github.com/AIR-DI/IVM)
- [DecisionNCE (ICML 2024): Embodied Multimodal Representations via Implicit Preference Learning](https://github.com/AIR-DI/DecisionNCE)
- [QPA (ICLR 2024 spotlight): Query-Policy Misalignment in Preference-Based Reinforcement Learning](https://github.com/AIR-DI/QPA)
- [ODICE (ICLR 2024 spotlight): Revealing the Mystery of Distribution Correction Estimation via Orthogonal-gradient Update](https://github.com/AIR-DI/ODICE-Pytorch)
- [FISOR (ICLR 2024): Safe Offline Reinforcement Learning with Feasibility-Guided Diffusion Model](https://github.com/AIR-DI/FISOR)
- [PROTO: Iterative Policy Regularized Offline-to-Online Reinforcement Learning](https://github.com/AIR-DI/PROTO)
- [OMIGA (NeurIPS 2023): Offline Multi-Agent RL with Implicit Global-to-Local Value Regularization](https://github.com/AIR-DI/OMIGA)
- [TSRL (NeurIPS 2023): Look Beneath the Surface: Exploiting Fundamental Symmetry for Sample-Efficient Offline RL](https://github.com/AIR-DI/TSRL)
- [SQL/EQL (ICLR 2023 oral): Offline RL with No OOD Actions: In-Sample Learning via Implicit Value Regularization](https://github.com/AIR-DI/IVR)
- [DOGE (ICLR 2023): When Data Geometry Meets Deep Function: Generalizing Offline Reinforcement Learning](https://github.com/AIR-DI/DOGE)
- [RGM (ICLR 2023): Mind the Gap: Offline Policy Optimization for Imperfect Rewards](https://github.com/AIR-DI/RGM)
- [H2O (NeurIPS 2022 spotlight): When to Trust Your Simulator: Dynamics-Aware Hybrid Offline-and-Online Reinforcement Learning](https://github.com/AIR-DI/H2O)
- [POR (NeurIPS 2022 oral): A Policy-Guided Imitation Approach for Offline Reinforcement Learning](https://github.com/AIR-DI/POR)
- [DWBC (ICML 2022): Discriminator-Weighted Offline Imitation Learning from Suboptimal Demonstrations](https://github.com/AIR-DI/DWBC)
- [DMIL (CoRL 2022): Discriminator-Guided Model-Based Offline Imitation Learning](https://github.com/AIR-DI/D2C) (available from D2C)
- [CPQ (AAAI 2022): Constraints Penalized Q-Learning for Safe Offline Reinforcement Learning](https://github.com/AIR-DI/CPQ)
- [DeepThermal (AAAI 2022): Combustion Optimization for Thermal Power Generating Units Using Offline Reinforcement Learning](https://github.com/AIR-DI/DeepThermal)
- [MOPP (IJCAI 2022): Model-Based Offline Planning with Trajectory Pruning](https://github.com/AIR-DI/MOPP)




Tools/Libraries:

- [D2C: Data-Driven Control Library](https://github.com/AIR-DI/D2C)
- [OneRL: Event-Driven Fully Distributed Reinforcement Learning Framework](https://github.com/AIR-DI/onerl)
- [OpenChat: Open-Source Language Models](https://github.com/AIR-DI/openchat)
